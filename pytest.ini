[pytest]
# Pytest configuration for the Crawler project

# Test discovery
testpaths = tests
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*

# Output and formatting
addopts = 
    --strict-markers
    --strict-config
    --verbose
    --tb=short
    --color=yes
    --durations=10
    --cov=src/crawler
    --cov-report=term-missing
    --cov-report=html:coverage_html
    --cov-report=xml
    --cov-fail-under=80

# Markers
markers =
    unit: Unit tests
    integration: Integration tests
    slow: Slow tests that take more than 5 seconds
    network: Tests that require network access
    database: Tests that require database access
    browser: Tests that require browser/crawl4ai
    cli: Tests for CLI functionality
    api: Tests for API endpoints
    benchmark: Benchmark tests for performance measurement
    edge_cases: Edge case tests for boundary conditions
    refactoring: Refactoring tests for code restructuring
    performance: Performance tests for system optimization
    validation: Validation tests for data integrity

# Async test configuration
asyncio_mode = auto

# Warnings
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::UserWarning:crawl4ai.*
    ignore::DeprecationWarning:bs4.*
    ignore::DeprecationWarning:pydantic.*

# Minimum Python version
minversion = 3.8

# Test timeout (seconds)
timeout = 300

# Coverage configuration
[coverage:run]
source = src/crawler
omit = 
    */tests/*
    */migrations/*
    */alembic/*
    */version.py
    */main.py

[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    if TYPE_CHECKING:

[coverage:html]
directory = coverage_html